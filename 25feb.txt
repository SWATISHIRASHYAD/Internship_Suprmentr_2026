'''
#What is classification?
Predicing the category.
ex:
email:spam or not spam
tumor:malignant or benign
student:pass or fail

output is discrete, not continuous
'''

'''
Logistic Regression:
Why not linear regression?
Linear regre output:-1,5,2.3,7.8,....
Logistic regression output: 0 or 1(binary classification)-sigmoid function

sigmoid function: f(z)=1/(1+e^-z)
it will convert any number into range between 0 and 1.

Logistic regression:
z=w1x1+w2x2+...+wnxn+b
then apply:prediction=sigmoid(z)

if prediction>0.5:class 1
else:class 0
'''

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score

#load dataset
data=load_breast_cancer()
X=data.data
y=data.target

print("Features shape: ",X.shape)
print("Target shape",y.shape)

#train test split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

#create model
model=LogisticRegression(max_iter=5000)

#train model
model.fit(X_train,y_train)

#predict
y_pred=model.predict(X_test)

#accuracy
accuracy=accuracy_score(y_test,y_pred)
print("Accuracy:",accuracy)

#confusion matrix
cm=confusion_matrix(y_test,y_pred)
print("Confusion Matrix:\n",cm)

'''
Confusion matrix:
[[TN,FN],
 [Fp,Tp]]
TP:True Positive
FP:False Positive
FN:False Negative
TN:True Negative
'''

#accuracy=(TP+TN)/(TP+FP+FN+TN)

#precision=TP/(TP+FP)

precision=precision_score(y_test,y_pred)
print("Precision:",precision)

#recall=TP/(TP+FN)
#out of actual positives, how many were correctly predicted as positive
recall=recall_score(y_test,y_pred)
print("Recall:",recall)



